
🎮🖐️ Play Temple Run & Subway Surfers Using Hand Gestures – No Touch Needed! 🤯🚀

Imagine controlling your favorite games like Temple Run or Subway Surfers using just your hand gestures – no keyboard, no mouse, just ✋ + 🧠!

I recently built a futuristic gesture-control system using Python, OpenCV, MediaPipe, and PyAutoGUI, and YES – it lets you play these games with your bare hands!

✨ Project Highlights:
✅ Real-time hand tracking using MediaPipe
✅ Recognizes thumb & index finger gestures for in-game actions (Jump, Slide, Turn)
✅ Sends keyboard commands to the game using PyAutoGUI
✅ Live feedback with gesture labels and a transparent UI overlay
✅ Supports both Temple Run & Subway Surfers for a next-gen gaming experience

🎮 Just move your hand:

☝️ Index Finger = Jump

👍 Thumb = Slide

🤜 Index + Thumb = Turn Left

🤛 Index + Thumb + Middle = Turn Right

🔧 Stack Used:
Python | OpenCV | MediaPipe | PyAutoGUI | matplotlib

📌 Use Cases Beyond Gaming:

Gesture-based accessibility systems

Touchless smart home interfaces

AR/VR gesture controls

Robotics + automation inputs

📽️ Demo coming soon on YouTube! (Drop your channel link)
🧠 Curious about the code? (Optional GitHub link)

Let me know what futuristic project YOU would connect this to! 🚀👇

#Python #GestureControl #AIProjects #OpenCV #MediaPipe #TempleRun #SubwaySurfers #GamingInnovation #TouchlessControl #TechForGood #FutureIsNow #MachineLearning #Automation #ARVR #HumanComputerInteraction #LinkedInTech
