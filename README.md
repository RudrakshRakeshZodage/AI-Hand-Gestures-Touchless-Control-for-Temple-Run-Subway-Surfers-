
ğŸ®ğŸ–ï¸ Play Temple Run & Subway Surfers Using Hand Gestures â€“ No Touch Needed! ğŸ¤¯ğŸš€

Imagine controlling your favorite games like Temple Run or Subway Surfers using just your hand gestures â€“ no keyboard, no mouse, just âœ‹ + ğŸ§ !

I recently built a futuristic gesture-control system using Python, OpenCV, MediaPipe, and PyAutoGUI, and YES â€“ it lets you play these games with your bare hands!

âœ¨ Project Highlights:
âœ… Real-time hand tracking using MediaPipe
âœ… Recognizes thumb & index finger gestures for in-game actions (Jump, Slide, Turn)
âœ… Sends keyboard commands to the game using PyAutoGUI
âœ… Live feedback with gesture labels and a transparent UI overlay
âœ… Supports both Temple Run & Subway Surfers for a next-gen gaming experience

ğŸ® Just move your hand:

â˜ï¸ Index Finger = Jump

ğŸ‘ Thumb = Slide

ğŸ¤œ Index + Thumb = Turn Left

ğŸ¤› Index + Thumb + Middle = Turn Right

ğŸ”§ Stack Used:
Python | OpenCV | MediaPipe | PyAutoGUI | matplotlib

ğŸ“Œ Use Cases Beyond Gaming:

Gesture-based accessibility systems

Touchless smart home interfaces

AR/VR gesture controls

Robotics + automation inputs

ğŸ“½ï¸ Demo coming soon on YouTube! (Drop your channel link)
ğŸ§  Curious about the code? (Optional GitHub link)

Let me know what futuristic project YOU would connect this to! ğŸš€ğŸ‘‡

#Python #GestureControl #AIProjects #OpenCV #MediaPipe #TempleRun #SubwaySurfers #GamingInnovation #TouchlessControl #TechForGood #FutureIsNow #MachineLearning #Automation #ARVR #HumanComputerInteraction #LinkedInTech
